{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from utils.utils import read_dataset\n",
    "from utils.utils import create_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier():\n",
    "    x_train = datasets_dict[dataset_name][0]\n",
    "    y_train = datasets_dict[dataset_name][1]\n",
    "    x_test = datasets_dict[dataset_name][2]\n",
    "    y_test = datasets_dict[dataset_name][3]\n",
    "    \n",
    "    nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
    "    #print('Number of Classes: %s' % nb_classes)\n",
    "    \n",
    "    #one-hot-encoding\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "    \n",
    "    # save orignal y because later we will use binary\n",
    "    y_true = np.argmax(y_test, axis=1) #See if this is really needed later\n",
    "    \n",
    "    if len(x_train.shape) == 2: #if univariate, check to see if this may make things harder later on\n",
    "        #adds dimension making it multivariate with one dimension\n",
    "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "        \n",
    "    input_shape = x_train.shape\n",
    "    print(input_shape)\n",
    "    classifier = create_classifier(classifier_name, input_shape, nb_classes, output_dir, True)\n",
    "    \n",
    "    classifier.fit(x_train, y_train, x_test, y_test, y_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(classifier_name, input_shape, nb_classes, output_dir, verbose=False):\n",
    "    if classifier_name == 'mlp':\n",
    "        from models import mlp\n",
    "        return mlp.Classifier_MLP(output_dir, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == 'lstmfcn':\n",
    "        from models import lstmfcn\n",
    "        return lstmfcn.Classifier_LSTMFCN(output_dir, input_shape, nb_classes,  verbose)\n",
    "    if classifier_name == 'emn':\n",
    "        return Classifier_EMN(output_dir, nb_classes,input_shape, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_win = 'C:/Users/worf9_000/Desktop/bs-thesis/experiments'\n",
    "root_dir_arch = '/home/worf/Work/bs-thesis/experiments'\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "dataset_name = 'ShapesAll'\n",
    "classifier_name = 'emn'\n",
    "\n",
    "datasets_dict = read_dataset(root_dir, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  ShapesAll emn\n",
      "(600, 512, 1)\n",
      "[0.6, 0.7]\n",
      "512\n",
      "[307, 358]\n",
      "600\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_5 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-324c4bb449eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdatasets_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mfit_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DONE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-a80d530de5a4>\u001b[0m in \u001b[0;36mfit_classifier\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-545bb484c7a9>\u001b[0m in \u001b[0;36mcreate_classifier\u001b[1;34m(classifier_name, input_shape, nb_classes, output_dir, verbose)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlstmfcn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClassifier_LSTMFCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclassifier_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emn'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mClassifier_EMN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-b72e50c04ac2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, nb_classes, input_shape, verbose)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ratio'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-b72e50c04ac2>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self, input_shape, nb_classes, len_series)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mres_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconnectivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaky\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspectral_radius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         x_layer_1 = keras.layers.Conv2D(120, (nb_rows[0], nb_cols), kernel_initializer='lecun_uniform', activation='relu',\n\u001b[0m\u001b[0;32m     45\u001b[0m                                        padding='valid', strides=(1,1), data_format = 'channels_last')(res_layer)\n\u001b[0;32m     46\u001b[0m         \u001b[0mx_layer_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_layer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1090\u001b[0m       \u001b[1;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m       \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    192\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_5 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 32]"
     ]
    }
   ],
   "source": [
    "output_dir = root_dir + '/results/' + classifier_name + '/UCRArchive_2018/' + dataset_name + '/'\n",
    "\n",
    "test_dir_df_metrics = output_dir + 'df_metrics.csv'\n",
    "\n",
    "print('Method: ', dataset_name, classifier_name)\n",
    "\n",
    "if os.path.exists(test_dir_df_metrics):\n",
    "    print('Already done')\n",
    "#else:\n",
    "    \n",
    "create_directory(output_dir)\n",
    "datasets_dict = read_dataset(root_dir, dataset_name)\n",
    "    \n",
    "fit_classifier()\n",
    "    \n",
    "print('DONE')\n",
    "    \n",
    "create_directory(output_dir + '/DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from layers.reservoir import Reservoir\n",
    "\n",
    "from utils.utils import save_logs\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "class Classifier_EMN:\n",
    "    def __init__(self, output_dir, nb_classes, input_shape, verbose):\n",
    "        self.output_dir = output_dir\n",
    "        self.nb_classes = nb_classes\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        #Hyperparameters ESN\n",
    "        self.esn_config = {'units':32, 'connect':0.7,'IS':0.1,\"spectral\":0.9,'leaky':1}\n",
    "        \n",
    "        #Hyperparameters Convolutions\n",
    "        self.conv_config = {'epoch':500,'batch':25,'ratio':[0.6,0.7]}\n",
    "        \n",
    "        self.model = self.build_model(input_shape, nb_classes, input_shape[1])\n",
    "        self.model.summary()\n",
    "        \n",
    "        \n",
    "    def build_model(self, input_shape, nb_classes, len_series):\n",
    "        ratio = self.conv_config['ratio']\n",
    "        print(ratio)\n",
    "        print(len_series)\n",
    "        nb_rows = [np.int(ratio[0]*len_series),np.int(ratio[1]*len_series)]\n",
    "        print(nb_rows)\n",
    "        nb_cols = input_shape[0]\n",
    "        print(nb_cols)\n",
    "        \n",
    "        input_layer = keras.layers.Input(input_shape[1:])\n",
    "        \n",
    "        res_layer = tfa.layers.ESN(units=32,connectivity=0.7,leaky=1,spectral_radius=0.9,use_bias=False)(input_layer)\n",
    "        \n",
    "        x_layer_1 = keras.layers.Conv2D(120, (nb_rows[0], nb_cols), kernel_initializer='lecun_uniform', activation='relu',\n",
    "                                       padding='valid', strides=(1,1), data_format = 'channels_last')(res_layer)\n",
    "        x_layer_1 = keras.layers.GlobalMaxPooling2D(data_format = 'channels_first')(x_layer_1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_layer_1 = keras.layers.Conv2D(120, (nb_rows[1], nb_cols), kernel_initializer='lecun_uniform', activation='relu',\n",
    "                                       padding='valid', strides=(1,1), data_format = 'channels_last')(res_layer)\n",
    "        y_layer_1 = keras.layers.GlobalMaxPooling2D(data_format = 'channels_last')(y_layer_1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        concat_layer = keras.layers.concatenate([x_layer_1, y_layer_1])\n",
    "        concat_layer = keras.layers.Dropout(0.25)(concat_layer)\n",
    "        \n",
    "        output_layer = keras.layers.Dense(nb_classes, kernel_initializer='lecun_uniform', activation='softmax')(concat_layer)\n",
    "        \n",
    "        model = keras.models.Model(input_layer, output_layer)\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "        \n",
    "        self.callbacks = [TqdmCallback(verbose=0)]\n",
    "        \n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def reshape_shuffle(self, x_train, y_train, nb_samples, res_units, len_series):\n",
    "\n",
    "        #Generate template for train data\n",
    "        train_data = np.zeros((nb_samples, 1, len_series, res_units))\n",
    "        train_labels = np.zeros((nb_samples, self.nb_classes))\n",
    "\n",
    "        #Generate Shuffle template\n",
    "        L_train = [x_train for x_train in range(nb_samples)] #Array with size==samples, every value==index \n",
    "        np.random.shuffle(L_train)\n",
    "        \n",
    "        #For every series -> shuffle train and labels\n",
    "        for m in range(nb_samples):\n",
    "            train_data[m,0,:,:] = x_train[L_train[m],:,:] \n",
    "            train_labels[m,:] = y_train[L_train[m],:]\n",
    "        \n",
    "        return train_data, train_labels      \n",
    "    \n",
    "    def ff_esn(self, x_train, x_test):\n",
    "        units = self.esn_config['units']\n",
    "        connectivity = self.esn_config['connect']\n",
    "        IS = self.esn_config['IS']\n",
    "        spectral_radius = self.esn_config['spectral']\n",
    "        leaky = self.esn_config['leaky']\n",
    "        n_in = 1\n",
    "        \n",
    "        escnn = Reservoir(units, n_in, IS, spectral_radius, connectivity, leaky)\n",
    "        echoes_train = escnn.set_weights(x_train)\n",
    "        echoes_test = escnn.set_weights(x_test)\n",
    "        \n",
    "        return echoes_train, echoes_test\n",
    "        \n",
    "    def fit(self, x_train, y_train, x_val, y_val, y_true):        \n",
    "        \n",
    "        #3. Train Model\n",
    "        batch = self.conv_config['batch']\n",
    "        epoch = self.conv_config['epoch']\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        hist = self.model.fit(x_train, y_train, batch_size=batch, epochs=epoch,\n",
    "            verbose=False, validation_data=(x_val,y_val), callbacks=self.callbacks)\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        y_pred = self.model.predict(x_val)\n",
    "\n",
    "        # convert the predicted from binary to integer\n",
    "        y_pred = np.argmax(y_pred , axis=1)\n",
    "\n",
    "        save_logs(self.output_dir, hist, y_pred, y_true, duration, self.verbose, lr=False)\n",
    "\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
