{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from utils.utils import read_dataset\n",
    "from utils.utils import create_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier():\n",
    "    x_train = datasets_dict[dataset_name][0]\n",
    "    y_train = datasets_dict[dataset_name][1]\n",
    "    x_test = datasets_dict[dataset_name][2]\n",
    "    y_test = datasets_dict[dataset_name][3]\n",
    "    \n",
    "    nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
    "    #print('Number of Classes: %s' % nb_classes)\n",
    "    \n",
    "    #one-hot-encoding\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "    \n",
    "    # save orignal y because later we will use binary\n",
    "    y_true = np.argmax(y_test, axis=1) #See if this is really needed later\n",
    "    \n",
    "    if len(x_train.shape) == 2: #if univariate, check to see if this may make things harder later on\n",
    "        #adds dimension making it multivariate with one dimension\n",
    "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "        \n",
    "    input_shape = x_train.shape\n",
    "    print(input_shape)\n",
    "    classifier = create_classifier(classifier_name, input_shape, nb_classes, output_dir, True)\n",
    "    \n",
    "    classifier.fit(x_train, y_train, x_test, y_test, y_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(classifier_name, input_shape, nb_classes, output_dir, verbose=False):\n",
    "    if classifier_name == 'mlp':\n",
    "        from models import mlp\n",
    "        return mlp.Classifier_MLP(output_dir, input_shape, nb_classes, verbose)\n",
    "    if classifier_name == 'lstmfcn':\n",
    "        from models import lstmfcn\n",
    "        return lstmfcn.Classifier_LSTMFCN(output_dir, input_shape, nb_classes,  verbose)\n",
    "    if classifier_name == 'emn':\n",
    "        return Classifier_EMN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_win = 'C:/Users/worf9_000/Desktop/bs-thesis/experiments'\n",
    "root_dir_arch = '/home/worf/Work/bs-thesis/experiments'\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "dataset_name = 'ShapesAll'\n",
    "classifier_name = 'emn'\n",
    "\n",
    "datasets_dict = read_dataset(root_dir, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  ShapesAll emn\n",
      "(600, 512, 1)\n",
      "[0.6, 0.7]\n",
      "512\n",
      "[307, 358]\n",
      "600\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_5 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-324c4bb449eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdatasets_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mfit_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DONE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-a80d530de5a4>\u001b[0m in \u001b[0;36mfit_classifier\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-545bb484c7a9>\u001b[0m in \u001b[0;36mcreate_classifier\u001b[1;34m(classifier_name, input_shape, nb_classes, output_dir, verbose)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlstmfcn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClassifier_LSTMFCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclassifier_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'emn'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mClassifier_EMN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-b72e50c04ac2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, nb_classes, input_shape, verbose)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ratio'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-b72e50c04ac2>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self, input_shape, nb_classes, len_series)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mres_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconnectivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaky\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspectral_radius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         x_layer_1 = keras.layers.Conv2D(120, (nb_rows[0], nb_cols), kernel_initializer='lecun_uniform', activation='relu',\n\u001b[0m\u001b[0;32m     45\u001b[0m                                        padding='valid', strides=(1,1), data_format = 'channels_last')(res_layer)\n\u001b[0;32m     46\u001b[0m         \u001b[0mx_layer_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_layer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1090\u001b[0m       \u001b[1;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m       \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    192\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_5 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 32]"
     ]
    }
   ],
   "source": [
    "output_dir = root_dir + '/results/' + classifier_name + '/UCRArchive_2018/' + dataset_name + '/'\n",
    "\n",
    "test_dir_df_metrics = output_dir + 'df_metrics.csv'\n",
    "\n",
    "print('Method: ', dataset_name, classifier_name)\n",
    "\n",
    "if os.path.exists(test_dir_df_metrics):\n",
    "    print('Already done')\n",
    "#else:\n",
    "    \n",
    "create_directory(output_dir)\n",
    "datasets_dict = read_dataset(root_dir, dataset_name)\n",
    "    \n",
    "fit_classifier()\n",
    "    \n",
    "print('DONE')\n",
    "    \n",
    "create_directory(output_dir + '/DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "import numpy as np\n",
    "\n",
    "from layers.reservoir import Reservoir\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class Classifier_EMN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, res_units=32, \n",
    "                 spectral_radius=0.9, input_scaling=0.1, \n",
    "                 connectivity=0.3, leaky=1, n_in=1,\n",
    "                 epochs=500, batch_size=25, \n",
    "                 ratio=[0.1,0.2], num_filter=120,\n",
    "                 verbose = True):\n",
    "        self.res_units = res_units\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scaling = input_scaling\n",
    "        self.connectivity = connectivity\n",
    "        self.leaky = leaky\n",
    "        self.n_in = n_in\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.ratio = ratio\n",
    "        self.num_filter = num_filter\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_model(self, input_shape, nb_classes, len_series):\n",
    "        nb_rows = [np.int(self.ratio[0]*len_series),np.int(self.ratio[1]*len_series)]\n",
    "        nb_cols = input_shape[2]\n",
    "        \n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "        \n",
    "        x_layer_1 = keras.layers.Conv2D(self.num_filter, (nb_rows[0], nb_cols), kernel_initializer='lecun_uniform', activation='relu',\n",
    "                                       padding='valid', strides=(1,1), data_format = 'channels_last')(input_layer)\n",
    "        x_layer_1 = keras.layers.GlobalMaxPooling2D(data_format = 'channels_first')(x_layer_1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_layer_1 = keras.layers.Conv2D(self.num_filter, (nb_rows[1], nb_cols), kernel_initializer='lecun_uniform', activation='relu',\n",
    "                                       padding='valid', strides=(1,1), data_format = 'channels_last')(input_layer)\n",
    "        y_layer_1 = keras.layers.GlobalMaxPooling2D(data_format = 'channels_last')(y_layer_1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        concat_layer = keras.layers.concatenate([x_layer_1, y_layer_1])\n",
    "        concat_layer = keras.layers.Dropout(0.25)(concat_layer)\n",
    "        \n",
    "        output_layer = keras.layers.Dense(nb_classes, kernel_initializer='lecun_uniform', activation='softmax')(concat_layer)\n",
    "        \n",
    "        model = keras.models.Model(input_layer, output_layer)\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "        \n",
    "        self.callbacks_ = []\n",
    "        \n",
    "        if self.verbose:\n",
    "            self.callbacks_.append(TqdmCallback(verbose=0))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def reshape_shuffle(self, x_train, y_train, nb_samples, nb_classes, len_series):\n",
    "\n",
    "        #Generate template for train data\n",
    "        train_data = np.zeros((nb_samples, 1, len_series, self.res_units))\n",
    "        train_labels = np.zeros((nb_samples, nb_classes))\n",
    "\n",
    "        #Generate Shuffle template\n",
    "        L_train = [x_train for x_train in range(nb_samples)] #Array with size==samples, every value==index \n",
    "        np.random.shuffle(L_train)\n",
    "        \n",
    "        #For every series -> shuffle train and labels\n",
    "        for m in range(nb_samples):\n",
    "            train_data[m,0,:,:] = x_train[L_train[m],:,:] \n",
    "            train_labels[m,:] = y_train[L_train[m],:]\n",
    "        \n",
    "        return train_data, train_labels      \n",
    "        \n",
    "    def fit(self, x, y):              \n",
    "        self.escnn_ = Reservoir(self.res_units, self.n_in, \n",
    "                                self.input_scaling, self.spectral_radius, \n",
    "                                self.connectivity, self.leaky, verbose = self.verbose)\n",
    "        x = self.escnn_.set_weights(x)\n",
    "\n",
    "        nb_samples_x = np.shape(x)[0]\n",
    "        len_series = x.shape[1]\n",
    "        input_shape = (len_series, self.res_units, 1)\n",
    "        nb_classes = len(np.unique(np.argmax(y,axis=1)))\n",
    "\n",
    "        x, y = self.reshape_shuffle(x, y, nb_samples_x, nb_classes, len_series)\n",
    "\n",
    "        # From NCHW to NHWC\n",
    "        x = tf.transpose(x, [0, 2, 3, 1])\n",
    "        \n",
    "        self.model = self.build_model(input_shape, nb_classes, len_series)\n",
    "        \n",
    "        hist = self.model.fit(x, y, batch_size=self.batch_size, epochs=self.epochs,\n",
    "            verbose=False, callbacks=self.callbacks_)\n",
    "\n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        x = self.escnn_.set_weights(x)\n",
    "        nb_samples_test = np.shape(x)[0]\n",
    "        len_series = x.shape[1]\n",
    "        x = np.reshape(x, (nb_samples_test, len_series, self.res_units, 1))\n",
    "        \n",
    "        y_pred = self.model.predict(x)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        x = self.escnn_.set_weights(x)\n",
    "        nb_samples_x = np.shape(x)[0]\n",
    "        len_series = x.shape[1]\n",
    "        x = np.reshape(x, (nb_samples_x, len_series, self.res_units, 1))\n",
    "        \n",
    "        outputs = self.model.evaluate(x, y, verbose=False)\n",
    "        if not isinstance(outputs, list):\n",
    "            outputs = [outputs]\n",
    "        for name, output in zip(self.model.metrics_names, outputs):\n",
    "            if name in ['accuracy', 'acc']:\n",
    "                return output\n",
    "        raise ValueError('The model is not configured to compute accuracy. '\n",
    "                         'You should pass `metrics=[\"accuracy\"]` to '\n",
    "                         'the `model.compile()` method.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "dataset_name = 'Coffee'\n",
    "datasets_dict = read_dataset(root_dir, dataset_name)\n",
    "x_train = datasets_dict[dataset_name][0]\n",
    "y_train = datasets_dict[dataset_name][1]\n",
    "x_test = datasets_dict[dataset_name][2]\n",
    "y_test = datasets_dict[dataset_name][3]\n",
    "\n",
    "#one-hot-encoding\n",
    "enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25,\n",
       " 'connectivity': 0.3,\n",
       " 'epochs': 500,\n",
       " 'input_scaling': 0.1,\n",
       " 'leaky': 1,\n",
       " 'n_in': 1,\n",
       " 'num_filter': 120,\n",
       " 'ratio': [0.1, 0.2],\n",
       " 'res_units': 32,\n",
       " 'spectral_radius': 0.9,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_scaling = [0.1,1]\n",
    "connectivity = [0.3,0.7]\n",
    "param_grid_1 = dict(input_scaling = input_scaling, connectivity=connectivity)\n",
    "emn_stage_1 = Classifier_EMN(verbose=False)\n",
    "emn_stage_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ............connectivity=0.3, input_scaling=0.1; total time=  11.3s\n",
      "[CV 2/3] END ............connectivity=0.3, input_scaling=0.1; total time=  11.8s\n",
      "[CV 3/3] END ............connectivity=0.3, input_scaling=0.1; total time=  12.0s\n",
      "[CV 1/3] END ..............connectivity=0.3, input_scaling=1; total time=  11.4s\n",
      "[CV 2/3] END ..............connectivity=0.3, input_scaling=1; total time=  11.9s\n",
      "[CV 3/3] END ..............connectivity=0.3, input_scaling=1; total time=  12.1s\n",
      "[CV 1/3] END ............connectivity=0.7, input_scaling=0.1; total time=  11.4s\n",
      "[CV 2/3] END ............connectivity=0.7, input_scaling=0.1; total time=  12.0s\n",
      "[CV 3/3] END ............connectivity=0.7, input_scaling=0.1; total time=  11.9s\n",
      "[CV 1/3] END ..............connectivity=0.7, input_scaling=1; total time=  11.7s\n",
      "[CV 2/3] END ..............connectivity=0.7, input_scaling=1; total time=  12.0s\n",
      "[CV 3/3] END ..............connectivity=0.7, input_scaling=1; total time=  12.0s\n",
      "Best: 0.900000 using {'connectivity': 0.7, 'input_scaling': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid_1 = GridSearchCV(estimator=emn_stage_1, param_grid=param_grid_1, cv=3, verbose=3)\n",
    "grid_1_result = grid_1.fit(x_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_1_result.best_score_, grid_1_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 3,\n",
       " 'error_score': nan,\n",
       " 'estimator__batch_size': 25,\n",
       " 'estimator__connectivity': 0.7,\n",
       " 'estimator__epochs': 500,\n",
       " 'estimator__input_scaling': 0.1,\n",
       " 'estimator__leaky': 1,\n",
       " 'estimator__n_in': 1,\n",
       " 'estimator__num_filter': 120,\n",
       " 'estimator__ratio': [0.1, 0.2],\n",
       " 'estimator__res_units': 32,\n",
       " 'estimator__spectral_radius': 0.9,\n",
       " 'estimator__verbose': False,\n",
       " 'estimator': Classifier_EMN(connectivity=0.7, verbose=False),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'ratio': [[0.1, 0.2], [0.3, 0.4], [0.5, 0.6], [0.7, 0.8]]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 3}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = [[0.1, 0.2], [0.3, 0.4], [0.5, 0.6], [0.7, 0.8]]\n",
    "param_grid_2 = dict(ratio = ratio)\n",
    "emn_stage_2 = grid_1_result.best_estimator_\n",
    "grid_2 = GridSearchCV(estimator=emn_stage_2, param_grid=param_grid_2, cv=3, verbose=3)\n",
    "grid_2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ...............................ratio=[0.1, 0.2]; total time=  11.3s\n",
      "[CV 2/3] END ...............................ratio=[0.1, 0.2]; total time=  11.6s\n",
      "[CV 3/3] END ...............................ratio=[0.1, 0.2]; total time=  11.7s\n",
      "[CV 1/3] END ...............................ratio=[0.3, 0.4]; total time=   9.6s\n",
      "[CV 2/3] END ...............................ratio=[0.3, 0.4]; total time=  10.3s\n",
      "[CV 3/3] END ...............................ratio=[0.3, 0.4]; total time=  10.1s\n",
      "[CV 1/3] END ...............................ratio=[0.5, 0.6]; total time=   8.4s\n",
      "[CV 2/3] END ...............................ratio=[0.5, 0.6]; total time=   8.6s\n",
      "[CV 3/3] END ...............................ratio=[0.5, 0.6]; total time=   8.8s\n",
      "[CV 1/3] END ...............................ratio=[0.7, 0.8]; total time=   5.9s\n",
      "[CV 2/3] END ...............................ratio=[0.7, 0.8]; total time=   6.2s\n",
      "[CV 3/3] END ...............................ratio=[0.7, 0.8]; total time=   6.3s\n",
      "Best: 0.900000 using {'ratio': [0.5, 0.6]}\n"
     ]
    }
   ],
   "source": [
    "grid_2_result = grid_2.fit(x_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_2_result.best_score_, grid_2_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier_EMN(connectivity=0.7, ratio=[0.5, 0.6], verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = grid_2_result.best_estimator_\n",
    "final.get_params()\n",
    "final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25,\n",
       " 'connectivity': 0.7,\n",
       " 'epochs': 500,\n",
       " 'input_scaling': 0.1,\n",
       " 'leaky': 1,\n",
       " 'n_in': 1,\n",
       " 'num_filter': 120,\n",
       " 'ratio': [0.5, 0.6],\n",
       " 'res_units': 32,\n",
       " 'spectral_radius': 0.9,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
